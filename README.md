# Innovations in Dropout Techniques with Sector-wise and LRP-guided Approaches
This repository is the official implementation of "Enhancing Generalization in Neural Networks: Innovations in Dropout Techniques with Sector-wise and LRP-guided Approaches" paper.
The Sector-wise dropout approach systematically divides the nodes in each layer into sectors, applying deactivation based on a fixed dropout probability to ensure a more structured network architecture. LRP-guided Dropout leverages scores from Layer-wise Relevance Propagation (LRP), computed subsequent to parameter updates, to selectively deactivate nodes positioned within the highest percentile of LRP scores. Through empirical evaluation, we establish that these innovative approaches markedly enhance the balance and generalization capacity of neural networks, thus representing a significant progression in mitigating the overfitting conundrum.

<img width="753" alt="image" src="https://github.com/csulb-datascience/Sector-wise-and-LRP-guided/assets/44173994/d499504f-4b98-49d8-9d2d-934f9c350cc9">

A conceptual diagram of the classical dropout method and the proposed methods. (a) Standard network. (b) Sub-network
generated by the classical dropout. (c) Nodes within each layer form sectors, and a subset of these nodes is randomly dropped at a given dropout rate p. (d) LRP relevance scores are computed for all nodes in each layer. Subsequently, a proportion of top p Ã— 100% of the nodes in the layer are selectively dropped out, based on their LRP relevance scores.
